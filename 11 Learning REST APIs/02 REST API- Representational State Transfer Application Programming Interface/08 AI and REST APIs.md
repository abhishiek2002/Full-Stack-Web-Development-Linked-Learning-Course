# AI and REST APIs

REST APIs used to be a subject of interest mainly for front- and back-end web developers because they’re the ones who most often built applications interacting with these data sources. That all changed with the introduction of generative AI.

Every major AI provider uses REST as their API protocol, and their API endpoints and properties are rapidly standardizing to make it easy for users to switch between AI models and providers without having to rewrite their entire codebase. As a result, the scope of people interested in learning about REST APIs has dramatically widened and deepened.

So why REST? While we don’t have detailed accounts of the exact internal decision process at AI companies that led to this choice, we can make some educated guesses.

The nondeterministic nature of AI is the most obvious reason: make a request to a full-featured AI API, and the response may include a wide variety of properties including completions, images, tool calls, streaming data, and more. Knowing this, REST’s default of returning all the data is exactly what developers want. That way, they can build custom software to sort through the response and handle this nondeterminism in a clean way. 

The broad set of features in REST is another reason: in our library example, an AI API would be a writer sitting in the library typing out custom text based on your requests. It’s fancy, it can be useful, but it also takes time—far more time than a regular request for a book—and users rarely have the patience to stare at a blank page while they wait for the text to be fully written out. The solution? Server-Sent Events (SSE), a REST-compatible streaming solution that every major AI service provider has adopted. Using the standard text/event-stream content type, AI APIs stream responses word by word, creating the typing effect we all became accustomed to with the introduction of ChatGPT. 

Authentication also goes on the list. To interact with most AI REST APIs, all you need is a standard bearer key passed in the Authorization header. This stands in contrast to the industry standard of complex multi-step OAuth flows or similar. This removes pretty much all friction when experimenting with these AIs, but introduces complexities at the production end because passing keys in the header of a request is not secure. The tradeoff here was clearly on developer simplicity over production security, and we are already starting to see a shift in this paradigm towards more secure (and cumbersome) authorization approaches.

All that said, the most important factor is probably the stateless nature of REST and how well it aligns with how AI services work. Many AI models have no session or state when accessed through an API, so each request must include the complete context needed to generate a response. That means the same REST API endpoint can be used to send unique one-off requests or to mimic statefullness by passing in the entire conversation history with each new prompt without having to actually manage state. In one way, this is a big step backwards from how we’ve done things, but in another, it means control over the behaviour and user experience of each app is now squarely in the hands of the developer, which for a nondeterministic system is often the only practical solution. 

Bottom line, if you're building AI-powered apps, having a solid understanding of REST is essential. The principles that made REST the go-to protocol for traditional web applications have coincidentally made it the ideal solution for AI services: clear resource modeling, stateless interactions, and standard HTTP semantics. So in a very real way, AI has resurrected REST and elevated it to an even higher position in the world of coding.