Configuration management: From golden image to foil ball
- Let's take a look at the evolution of DevOps configuration management. In the early days, the dev and ops approaches were very separate. - In the beginning, or at least in the 1990s, commercial IT provisioning tools like Ghost, that allowed simple cloning of systems, were common and large integrated enterprise suites like Tivoli or HP were the enterprise's answer. I was in tech then and those weren't much fun. Respect to the old school. - Okay, well, some infrastructure as code tools for system configuration were developed but they didn't really move into wide use until during most of the 2000s, stuff like CFEngine, Puppet, and Chef, those are the three big ones. The first time Ernest and I ran across one of these was around 2005. Our Unix admin team started using CFEngine to roll out operating system configurations. - Yeah, and they refused to let us use it to roll out our application server configs to the same systems. A little reminder that no amount of tooling will fix a lack of collaboration and sharing. Fight the power. - [Left Speaker] Luckily, others also arose to fight the powers that be. In a 2009 article called "Golden Image or Foil Ball", Luke Kanies, founder of Puppet, argued that performing CM only by image management using prebuilt system images led to image sprawl and configuration drift. - [Right Speaker] The technical community largely agreed and shifted towards a stem cell system approach where initial server images were as minimal as possible. You'd create servers from these base images and then a declarative CM tool would pick up to automatically provision the rest of the system. Then this idempotent tool is run incrementally over time to prevent configuration drift and provide later updates. - Here's an example of the code the tool Chef uses to configure systems. These operating system-level provisioning tools use declarative idempotent DSLs to define desired system configuration and then the systems automatically converge their state to them. - As virtualization gave way to cloud, all these tools quickly became a standard practice. If you're only getting in new servers once in a while and it takes weeks to get 'em set up anyway, it seems fine to use manual runbooks or ad hoc automation for setups. But now with cloud server instances coming and going dynamically and the move to distributed systems causing the raw number of virtual servers to grow exponentially, automated server provisioning is table stakes to have a well-managed environment. - Yeah but there was a problem though, the problem of orchestration. The default run pattern of Puppet and Chef is for each server under management to wake up every 15 minutes, check a central server for desired changes, and then pull and apply them on its own. For something like a university lab full of independent systems without high availability requirements, that was totally fine. But for a typical distributed application system where you need all of your application servers to not all go down at the same time or maybe need to coordinate database changes with application changes, well, that's not so fine. - Requests for orchestration, to be honest, were initially met by the CM vendors with, "You don't need orchestration and if you think you do, "you don't understand configuration management." - Yeah, well, that meant that many of these tools weren't great for application deployment. Also, they didn't provision the virtual infrastructure itself. Though some of them added on bolt-on tools later to do so, they weren't infrastructure as code in the same way that their core system configuration functionality was. They mainly solved a problem for system administrators but not for the other folks in the value stream. - The only tool I knew about in the 2000s that anyone wanted to use for application deployment was a Ruby tool called Capistrano, which was pretty minimal but at least let developers specify which servers to deploy their applications to. - So we entered the 2010s with a pretty good solution for server-level configuration but the larger issues of provisioning, deployment and orchestration, well, they were still mostly manual or had these bespoke solutions created by one specific organization to ease the pain. - This led to a new wave of tools like Ansible and SaltStack that switched to a push mechanism to perform more explicitly orchestrated deployments, joining dev-friendly push deployment with the idempotence ideas of other CM tools. This automated systems changes using an explicit workflow. For example, run a schema change on the database first, then perform a rolling deployment of the application on one server at a time. And then, if it went well, change the DNS entry. - Yeah, this grew in popularity quickly. And these tools were either used by themselves or to drive Chef or Puppet recipe changes on target servers to get a little bit of the best of both worlds there. - Self-service orchestration and runbook tools like Rundeck also arose to provide repeatable compliant ways for these kinds of system activities to be initiated by people on demand. - The 2010s also brought a revolution in infrastructure provisioning and we'll explore that next.