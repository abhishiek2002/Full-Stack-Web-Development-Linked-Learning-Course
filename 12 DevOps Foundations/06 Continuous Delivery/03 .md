Five practices for continuous delivery
- Is continuous delivery, just like getting food delivered, but for IT? Tap a few buttons and bam, pizza. Tap a few more and bam, Kubernetes. - Now, okay, that's a pretty good analogy, but it takes work to set up the process to get there. The definitive work on continuous delivery is the excellent book of the same name by Jez Humble and Dave Farley, and we highly recommend it. A great quote from the book to think about is, "It's not how much you can deliver, but how little." - [Instructor] After you have meditated upon this truth, let's return to our pipeline. After the build stage, we have a deployment stage. It's first step is to deploy our latest successful build artifacts to a live environment that's as much of a copy of production as possible. You might call this environment CI, staging, test, or pre-production. At this point, the rest of your testing should happen and it should be automated as much as possible. - Let's talk about five techniques to be successful at continuous delivery. In the video on continuous integration, we discussed creating an artifact upon successful completion of the build. That artifact is whatever your technology stack uses, RPM or Debian package, MSI installers, Java WAR files, ZIP files. It's a version bundled of all your technical pieces of your component. - These artifacts shouldn't be rebuilt for staging, testing, and production environments. - Yeah, that's right. They get built once and then used in all environments. This way, you know all your testing steps are valid since they are all used by the same artifact. - [Instructor] Your artifacts also shouldn't be allowed to change along the way. They need to be stored and have permission set in such a way so that they're immutable. - In the continuous delivery pipelines I've built, I set the permission so that only the CI system can write the artifact to the artifact repository, and the deployment system only has read access to that artifact. - We want artifacts to be immutable for two reasons. - Yeah, first, it's going to create trust between the teams when they're debugging an issue. You want dev and ops and QA, you want them to all have confidence that the underlying bits didn't change underneath them between stages. - Yeah, a quick checksum can prove that you're all looking at the exact same artifact version. - The second is auditability. One of the great parts about building a continuous delivery pipeline is that you can trace specific code versions in source control to a successful build artifact to a running system. - Rebuilding or changing an artifact along the way would break your auditability. Next, you want to have a pre-production environment that's as identical as possible to your production environment. - This environment needs to include all the load balancers, network settings, and security controls, along with all the data that matches production. - One of the reasons we move code to this environment is to do all the acceptance testing, smoke tests, and integration tests that are difficult to fully simulate on dev desktops or build servers. - Yeah, this gives you confidence that both your code and your deployment process is going to work correctly in production. - This brings up another crucial point. Your system needs to stop the pipeline if there's breakage at any point. - Yeah, if any stage fails, it should stop the next build phase from happening. If a build is broken, don't deploy. If a deploy is broken, don't release. Stop and fix it. - People will complain and say that, "Well, but I'm blocked from moving forward with my work until the build's fixed." But that's the point. You want to optimize for overall flow of your whole software delivery, not for each individual person. Tell them to pitch in and fix the problem. We talked about this in our "Infrastructure as Code" chapter, but it's good to reiterate that item potency is key for our deployments. That is, no matter how many times you run the same deployment, you get the exact same resulting system. - You may accomplish that using an immutable packaging mechanism like Docker containers or through using a configuration management tool like Puppet or Chef. But however you do it, you can't have variability in your pipeline or else you just can't trust it. - There are other things you have to consider to get good at continuous delivery, but these should get you started.